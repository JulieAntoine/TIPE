{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "df = pd.read_csv('2013-2014.csv')\n",
    "n = df.last_valid_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMETRES = ['FTHG','FTAG','FTR','HTHG','HTAG','HTR','HS','AS','HST','AST','HF','AF','HC','AC','HY','AY','HR','AR','B365H','B365D','B365A','BWH','BWD','BWA','IWH','IWD','IWA','LBH','LBD','LBA','PSH','PSD','PSA','WHH','WHD','WHA','SJH','SJD','SJA','VCH','VCD','VCA','Bb1X2','BbMxH','BbAvH','BbMxD','BbAvD','BbMxA','BbAvA','BbOU','BbMx>2.5','BbAv>2.5','BbMx<2.5','BbAv<2.5','BbAH','BbAHh','BbMxAHH','BbAvAHH','BbMxAHA','BbAvAHA','PSCH','PSCD','PSCA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENTREES = ['AwayTeam','HomeTeam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "SORTIES = ['FTR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(SORTIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['FTR'] == 'H',['FTR']] = float(2.0)\n",
    "df.loc[df['FTR'] == 'D',['FTR']] = float(1.0)\n",
    "df.loc[df['FTR'] == 'A',['FTR']] = float(0.0)\n",
    "df.loc[df['HTR'] == 'H',['HTR']] = float(2.0)\n",
    "df.loc[df['HTR'] == 'D',['HTR']] = float(1.0)\n",
    "df.loc[df['HTR'] == 'A',['HTR']] = float(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in PARAMETRES :\n",
    "    df.loc[df[param].isnull(),param] = np.round(df[param].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tautu\\AppData\\Local\\Temp\\ipykernel_12836\\3111569354.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['HomeTeam'].iloc[i] = l\n",
      "C:\\Users\\tautu\\AppData\\Local\\Temp\\ipykernel_12836\\3111569354.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['AwayTeam'].iloc[i] = l\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,n+1):\n",
    "    l=0\n",
    "    for r in range (0,len(df['HomeTeam'].iloc[i])):\n",
    "        l =+ float(ord((df['HomeTeam'].iloc[i])[r])*r)\n",
    "    df['HomeTeam'].iloc[i] = l\n",
    "\n",
    "for i in range(0,n+1):\n",
    "    l=0\n",
    "    for r in range (0,len(df['AwayTeam'].iloc[i])):\n",
    "        l =+ float(ord((df['AwayTeam'].iloc[i])[r])*r)\n",
    "    df['AwayTeam'].iloc[i] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Div         0\n",
       "Date        0\n",
       "HomeTeam    0\n",
       "AwayTeam    0\n",
       "FTHG        0\n",
       "           ..\n",
       "BbMxAHA     0\n",
       "BbAvAHA     0\n",
       "PSCH        0\n",
       "PSCD        0\n",
       "PSCA        0\n",
       "Length: 67, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1, random_state=217)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df[ENTREES].iloc[:int(n*0.8)]\n",
    "Y_train = df[SORTIES].iloc[:int(n*0.8)]\n",
    "X_test = df[ENTREES].iloc[int(n*0.8):]\n",
    "Y_test = df[SORTIES].iloc[int(n*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(np.float32)\n",
    "Y_train = Y_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "Y_test = Y_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(p):\n",
    "    if p == 0:\n",
    "        return 0\n",
    "    elif p == 1:\n",
    "        return 0\n",
    "    else:\n",
    "        return (- (p * np.log2(p) + (1 - p) * np.log2(1-p)))\n",
    "\n",
    "def information_gain(left_child, right_child):\n",
    "    parent = left_child + right_child\n",
    "    p_parent = parent.count(1) / len(parent) if len(parent) > 0 else 0\n",
    "    p_left = left_child.count(1) / len(left_child) if len(left_child) > 0 else 0\n",
    "    p_right = right_child.count(1) / len(right_child) if len(right_child) > 0 else 0\n",
    "    IG_p = entropy(p_parent)\n",
    "    IG_l = entropy(p_left)\n",
    "    IG_r = entropy(p_right)\n",
    "    return IG_p - len(left_child) / len(parent) * IG_l - len(right_child) / len(parent) * IG_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tree(tree, X_test):\n",
    "    feature_idx = tree['feature_idx']\n",
    "\n",
    "    if X_test[feature_idx] <= tree['split_point']:\n",
    "        if type(tree['left_split']) == dict:\n",
    "            return predict_tree(tree['left_split'], X_test)\n",
    "        else:\n",
    "            value = tree['left_split']\n",
    "            return value\n",
    "    else:\n",
    "        if type(tree['right_split']) == dict:\n",
    "            return predict_tree(tree['right_split'], X_test)\n",
    "        else:\n",
    "            return tree['right_split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bootstrap(X_train, Y_train):\n",
    "    bootstrap_indices = list(np.random.choice(range(len(X_train)), len(X_train), replace = True))\n",
    "    oob_indices = [i for i in range(len(X_train)) if i not in bootstrap_indices]\n",
    "    X_bootstrap = X_train.iloc[bootstrap_indices].values\n",
    "    Y_bootstrap = Y_train.iloc[bootstrap_indices]\n",
    "    X_oob = X_train.iloc[oob_indices].values\n",
    "    Y_oob = Y_train.iloc[oob_indices]\n",
    "    return X_bootstrap, Y_bootstrap, X_oob, Y_oob\n",
    "\n",
    "def oob_score(tree, X_test, Y_test):\n",
    "    mis_label = 0\n",
    "    for i in range(len(X_test)):\n",
    "        pred = predict_tree(tree, X_test[i])\n",
    "        if pred != Y_test[i]:\n",
    "            mis_label += 1\n",
    "    return mis_label / len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_split_point(X_bootstrap, Y_bootstrap, max_features):\n",
    "    feature_ls = list()\n",
    "    num_features = len(X_bootstrap[0])\n",
    "\n",
    "    while len(feature_ls) <= max_features:\n",
    "        feature_idx = random.sample(range(num_features), 1)\n",
    "    if feature_idx not in feature_ls:\n",
    "        feature_ls.extend(feature_idx)\n",
    "\n",
    "    best_info_gain = -999\n",
    "    node = None\n",
    "    for feature_idx in feature_ls:\n",
    "        for split_point in X_bootstrap[:,feature_idx]:\n",
    "            left_child = {'X_bootstrap': [], 'Y_bootstrap': []}\n",
    "            right_child = {'X_bootstrap': [], 'Y_bootstrap': []}\n",
    "\n",
    "        # split children for continuous variables\n",
    "        if type(split_point) in [int, float]:\n",
    "            for i, value in enumerate(X_bootstrap[:,feature_idx]):\n",
    "                if value <= split_point:\n",
    "                    left_child['X_bootstrap'].append(X_bootstrap[i])\n",
    "                    left_child['Y_bootstrap'].append(Y_bootstrap[i])\n",
    "                else:\n",
    "                    right_child['X_bootstrap'].append(X_bootstrap[i])\n",
    "                    right_child['Y_bootstrap'].append(Y_bootstrap[i])\n",
    "        # split children for categoric variables\n",
    "        else:\n",
    "            for i, value in enumerate(X_bootstrap[:,feature_idx]):\n",
    "                if value == split_point:\n",
    "                    left_child['X_bootstrap'].append(X_bootstrap[i])\n",
    "                    left_child['Y_bootstrap'].append(Y_bootstrap[i])\n",
    "                else:\n",
    "                    right_child['X_bootstrap'].append(X_bootstrap[i])\n",
    "                    right_child['Y_bootstrap'].append(Y_bootstrap[i])\n",
    "        split_info_gain = information_gain(left_child['Y_bootstrap'], right_child['Y_bootstrap'])\n",
    "        if split_info_gain > best_info_gain:\n",
    "            best_info_gain = split_info_gain\n",
    "            left_child['X_bootstrap'] = np.array(left_child['X_bootstrap'])\n",
    "            right_child['X_bootstrap'] = np.array(right_child['X_bootstrap'])\n",
    "            node = {'information_gain': split_info_gain,\n",
    "                    'left_child': left_child,\n",
    "                    'right_child': right_child,\n",
    "                    'split_point': split_point,\n",
    "                    'feature_idx': feature_idx}\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def terminal_node(node):\n",
    "    Y_bootstrap = node['Y_bootstrap']\n",
    "    pred = max(Y_bootstrap, key = Y_bootstrap.count)\n",
    "    return pred\n",
    "\n",
    "\n",
    "def split_node(node, max_features, min_samples_split, max_depth, depth):\n",
    "    left_child = node['left_child']\n",
    "    right_child = node['right_child']\n",
    "\n",
    "    del(node['left_child'])\n",
    "    del(node['right_child'])\n",
    "\n",
    "    if len(left_child['Y_bootstrap']) == 0 or len(right_child['Y_bootstrap']) == 0:\n",
    "        empty_child = {'Y_bootstrap': left_child['Y_bootstrap'] + right_child['Y_bootstrap']}\n",
    "        node['left_split'] = terminal_node(empty_child)\n",
    "        node['right_split'] = terminal_node(empty_child)\n",
    "        return\n",
    "\n",
    "    if depth >= max_depth:\n",
    "        node['left_split'] = terminal_node(left_child)\n",
    "        node['right_split'] = terminal_node(right_child)\n",
    "        return node\n",
    "\n",
    "    if len(left_child['X_bootstrap']) <= min_samples_split:\n",
    "        node['left_split'] = node['right_split'] = terminal_node(left_child)\n",
    "    else:\n",
    "        node['left_split'] = find_split_point(left_child['X_bootstrap'], left_child['Y_bootstrap'], max_features)\n",
    "        split_node(node['left_split'], max_depth, min_samples_split, max_depth, depth + 1)\n",
    "    if len(right_child['X_bootstrap']) <= min_samples_split:\n",
    "        node['right_split'] = node['left_split'] = terminal_node(right_child)\n",
    "    else:\n",
    "        node['right_split'] = find_split_point(right_child['X_bootstrap'], right_child['Y_bootstrap'], max_features)\n",
    "        split_node(node['right_split'], max_features, min_samples_split, max_depth, depth + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(X_bootstrap, Y_bootstrap, max_depth, min_samples_split, max_features):\n",
    "    root_node = find_split_point(X_bootstrap, Y_bootstrap, max_features)\n",
    "    split_node(root_node, max_features, min_samples_split, max_depth, 1)\n",
    "    return root_node\n",
    "\n",
    "def random_forest(X_train, Y_train, n_estimators, max_features, max_depth, min_samples_split):\n",
    "    tree_ls = list()\n",
    "    oob_ls = list()\n",
    "    for i in range(n_estimators):\n",
    "        X_bootstrap, Y_bootstrap, X_oob, Y_oob = draw_bootstrap(X_train, Y_train)\n",
    "        tree = build_tree(X_bootstrap, Y_bootstrap, max_features, max_depth, min_samples_split)\n",
    "        tree_ls.append(tree)\n",
    "        oob_error = oob_score(tree, X_oob, Y_oob)\n",
    "        oob_ls.append(oob_error)\n",
    "    print(\"OOB estimate: {:.2f}\".format(np.mean(oob_ls)))\n",
    "    return tree_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rf(tree_ls, X_test):\n",
    "    pred_ls = list()\n",
    "    for i in range(len(X_test)):\n",
    "        ensemble_preds = [predict_tree(tree, X_test.values[i]) for tree in tree_ls]\n",
    "        final_pred = max(ensemble_preds, key = ensemble_preds.count)\n",
    "        pred_ls.append(final_pred)\n",
    "    return np.array(pred_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 100\n",
    "max_features = 3\n",
    "max_depth = 10\n",
    "min_samples_split = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = random_forest(X_train, Y_train, n_estimators=100, max_features=3, max_depth=10, min_samples_split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=300,criterion='entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tautu\\AppData\\Local\\Temp\\ipykernel_12836\\4153405994.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(X_train,Y_train)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'unknown'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\tautu\\Documents\\TIPE 5_2\\TIPE-3.0\\code\\RandomForestClassifier (le bg du 92 t'as capté).ipynb Cellule 22\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/tautu/Documents/TIPE%205_2/TIPE-3.0/code/RandomForestClassifier%20%28le%20bg%20du%2092%20t%27as%20capt%C3%A9%29.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train,Y_train)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:371\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    365\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mSum of y is not strictly positive which \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mis necessary for Poisson regression.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    367\u001b[0m         )\n\u001b[0;32m    369\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[1;32m--> 371\u001b[0m y, expanded_class_weight \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_y_class_weight(y)\n\u001b[0;32m    373\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(y, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m!=\u001b[39m DOUBLE \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m y\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mcontiguous:\n\u001b[0;32m    374\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mascontiguousarray(y, dtype\u001b[39m=\u001b[39mDOUBLE)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:758\u001b[0m, in \u001b[0;36mForestClassifier._validate_y_class_weight\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    757\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_y_class_weight\u001b[39m(\u001b[39mself\u001b[39m, y):\n\u001b[1;32m--> 758\u001b[0m     check_classification_targets(y)\n\u001b[0;32m    760\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcopy(y)\n\u001b[0;32m    761\u001b[0m     expanded_class_weight \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\multiclass.py:200\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    192\u001b[0m y_type \u001b[39m=\u001b[39m type_of_target(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    193\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\n\u001b[0;32m    194\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    195\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmultilabel-sequences\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    199\u001b[0m ]:\n\u001b[1;32m--> 200\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnknown label type: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m y_type)\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: 'unknown'"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012987012987012988\n"
     ]
    }
   ],
   "source": [
    "acc=0\n",
    "for i in range (0,len(Y_test)):\n",
    "    if (results[i] == Y_test['FTR'].iloc[i]) :\n",
    "        acc =+ 1\n",
    "print(acc/len(Y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
