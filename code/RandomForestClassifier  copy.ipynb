{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "df = pd.read_csv('2013-2014.csv')\n",
    "n = df.last_valid_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMETRES = ['FTHG','FTAG','FTR','HTHG','HTAG','HTR','HS','AS','HST','AST','HF','AF','HC','AC','HY','AY','HR','AR','B365H','B365D','B365A','BWH','BWD','BWA','IWH','IWD','IWA','LBH','LBD','LBA','PSH','PSD','PSA','WHH','WHD','WHA','SJH','SJD','SJA','VCH','VCD','VCA','Bb1X2','BbMxH','BbAvH','BbMxD','BbAvD','BbMxA','BbAvA','BbOU','BbMx>2.5','BbAv>2.5','BbMx<2.5','BbAv<2.5','BbAH','BbAHh','BbMxAHH','BbAvAHH','BbMxAHA','BbAvAHA','PSCH','PSCD','PSCA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENTREES = ['HTHG','HTAG','HTR','AwayTeam','HomeTeam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SORTIES = ['FTR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(SORTIES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['FTR'] == 'H',['FTR']] = float(2.0)\n",
    "df.loc[df['FTR'] == 'D',['FTR']] = float(1.0)\n",
    "df.loc[df['FTR'] == 'A',['FTR']] = float(0.0)\n",
    "df.loc[df['HTR'] == 'H',['HTR']] = float(2.0)\n",
    "df.loc[df['HTR'] == 'D',['HTR']] = float(1.0)\n",
    "df.loc[df['HTR'] == 'A',['HTR']] = float(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in PARAMETRES :\n",
    "    df.loc[df[param].isnull(),param] = np.round(df[param].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tautu\\AppData\\Local\\Temp\\ipykernel_11240\\3111569354.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['HomeTeam'].iloc[i] = l\n",
      "C:\\Users\\tautu\\AppData\\Local\\Temp\\ipykernel_11240\\3111569354.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['AwayTeam'].iloc[i] = l\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,n+1):\n",
    "    l=0\n",
    "    for r in range (0,len(df['HomeTeam'].iloc[i])):\n",
    "        l =+ float(ord((df['HomeTeam'].iloc[i])[r])*r)\n",
    "    df['HomeTeam'].iloc[i] = l\n",
    "\n",
    "for i in range(0,n+1):\n",
    "    l=0\n",
    "    for r in range (0,len(df['AwayTeam'].iloc[i])):\n",
    "        l =+ float(ord((df['AwayTeam'].iloc[i])[r])*r)\n",
    "    df['AwayTeam'].iloc[i] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Div         0\n",
       "Date        0\n",
       "HomeTeam    0\n",
       "AwayTeam    0\n",
       "FTHG        0\n",
       "           ..\n",
       "BbMxAHA     0\n",
       "BbAvAHA     0\n",
       "PSCH        0\n",
       "PSCD        0\n",
       "PSCA        0\n",
       "Length: 67, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1, random_state=217)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df[ENTREES][:int(n*0.8)]\n",
    "Y_train = df[SORTIES][:int(n*0.8)]\n",
    "X_test = df[ENTREES][int(n*0.8):]\n",
    "Y_test = df[SORTIES][int(n*0.8):].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(p):\n",
    "    if p == 0:\n",
    "        return 0\n",
    "    elif p == 1:\n",
    "        return 0\n",
    "    else:\n",
    "        return (- (p * np.log2(p) + (1 - p) * np.log2(1-p)))\n",
    "\n",
    "def information_gain(left_child, right_child):\n",
    "    parent = left_child + right_child\n",
    "    p_parent = parent.count(1) / len(parent) if len(parent) > 0 else 0\n",
    "    p_left = left_child.count(1) / len(left_child) if len(left_child) > 0 else 0\n",
    "    p_right = right_child.count(1) / len(right_child) if len(right_child) > 0 else 0\n",
    "    IG_p = entropy(p_parent)\n",
    "    IG_l = entropy(p_left)\n",
    "    IG_r = entropy(p_right)\n",
    "    return IG_p - (len(left_child) / len(parent) * IG_l) - (len(right_child) / len(parent) * IG_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tree(tree, X_test):\n",
    "    feature_idx = tree['feature_idx']\n",
    "\n",
    "    if X_test[feature_idx] <= tree['split_point']:\n",
    "        if type(tree['left_split']) == dict:\n",
    "            return predict_tree(tree['left_split'], X_test)\n",
    "        else:\n",
    "            value = tree['left_split']\n",
    "            return value\n",
    "    else:\n",
    "        if type(tree['right_split']) == dict:\n",
    "            return predict_tree(tree['right_split'], X_test)\n",
    "        else:\n",
    "            return tree['right_split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bootstrap(X_train, Y_train):\n",
    "    bootstrap_indices = list(np.random.choice(range(len(X_train)), len(X_train), replace = True))\n",
    "    oob_indices = [i for i in range(len(X_train)) if i not in bootstrap_indices]\n",
    "    X_bootstrap = X_train.iloc[bootstrap_indices].values\n",
    "    Y_bootstrap = Y_train[bootstrap_indices]\n",
    "    X_oob = X_train.iloc[oob_indices].values\n",
    "    Y_oob = Y_train[oob_indices]\n",
    "    return X_bootstrap, Y_bootstrap, X_oob, Y_oob\n",
    "\n",
    "def oob_score(tree, X_test, Y_test):\n",
    "    mis_label = 0\n",
    "    for i in range(len(X_test)):\n",
    "        pred = predict_tree(tree, X_test[i])\n",
    "        if pred != Y_test[i]:\n",
    "            mis_label += 1\n",
    "    return mis_label / len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_split_point(X_bootstrap, Y_bootstrap, max_features):\n",
    "    feature_ls = list()\n",
    "    num_features = len(X_bootstrap[0])\n",
    "\n",
    "    while len(feature_ls) <= max_features:\n",
    "        feature_idx = random.sample(range(num_features), 1)\n",
    "        if feature_idx not in feature_ls:\n",
    "            feature_ls.extend(feature_idx)\n",
    "\n",
    "    best_info_gain = -999\n",
    "    node = None\n",
    "    for feature_idx in feature_ls:\n",
    "        for split_point in X_bootstrap[:,feature_idx]:\n",
    "            left_child = {'X_bootstrap': [], 'Y_bootstrap': []}\n",
    "            right_child = {'X_bootstrap': [], 'Y_bootstrap': []}\n",
    "\n",
    "            # split children for continuous variables\n",
    "            if type(split_point) in [int, float]:\n",
    "                for i, value in enumerate(X_bootstrap[:,feature_idx]):\n",
    "                    if value <= split_point:\n",
    "                        left_child['X_bootstrap'].append(X_bootstrap[i])\n",
    "                        left_child['Y_bootstrap'].append(Y_bootstrap[i])\n",
    "                    else:\n",
    "                        right_child['X_bootstrap'].append(X_bootstrap[i])\n",
    "                        right_child['Y_bootstrap'].append(Y_bootstrap[i])\n",
    "            # split children for categoric variables\n",
    "            else:\n",
    "                for i, value in enumerate(X_bootstrap[:,feature_idx]):\n",
    "                    if value == split_point:\n",
    "                        left_child['X_bootstrap'].append(X_bootstrap[i])\n",
    "                        left_child['Y_bootstrap'].append(Y_bootstrap[i])\n",
    "                    else:\n",
    "                        right_child['X_bootstrap'].append(X_bootstrap[i])\n",
    "                        right_child['Y_bootstrap'].append(Y_bootstrap[i])\n",
    "\n",
    "            split_info_gain = information_gain(left_child['Y_bootstrap'], right_child['Y_bootstrap'])\n",
    "            if split_info_gain > best_info_gain:\n",
    "                best_info_gain = split_info_gain\n",
    "                left_child['X_bootstrap'] = np.array(left_child['X_bootstrap'])\n",
    "                right_child['X_bootstrap'] = np.array(right_child['X_bootstrap'])\n",
    "                node = {'information_gain': split_info_gain,\n",
    "                        'left_child': left_child,\n",
    "                        'right_child': right_child,\n",
    "                        'split_point': split_point,\n",
    "                        'feature_idx': feature_idx}\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def terminal_node(node):\n",
    "    Y_bootstrap = node['Y_bootstrap']\n",
    "    pred = max(Y_bootstrap, key = Y_bootstrap.count)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_node(node, max_features, min_samples_split, max_depth, depth):\n",
    "    left_child = node['left_child']\n",
    "    right_child = node['right_child']\n",
    "\n",
    "    del(node['left_child'])\n",
    "    del(node['right_child'])\n",
    "\n",
    "    if len(left_child['Y_bootstrap']) == 0 or len(right_child['Y_bootstrap']) == 0:\n",
    "        empty_child = {'Y_bootstrap': left_child['Y_bootstrap'] + right_child['Y_bootstrap']}\n",
    "        node['left_split'] = terminal_node(empty_child)\n",
    "        node['right_split'] = terminal_node(empty_child)\n",
    "        return node\n",
    "\n",
    "    if depth >= max_depth:\n",
    "        node['left_split'] = terminal_node(left_child)\n",
    "        node['right_split'] = terminal_node(right_child)\n",
    "        return node\n",
    "\n",
    "    if len(left_child['X_bootstrap']) <= min_samples_split:\n",
    "        node['left_split'] = node['right_split'] = terminal_node(left_child)\n",
    "    else:\n",
    "        node['left_split'] = find_split_point(left_child['X_bootstrap'], left_child['Y_bootstrap'], max_features)\n",
    "        split_node(node['left_split'], max_depth, min_samples_split, max_depth, depth + 1)\n",
    "    if len(right_child['X_bootstrap']) <= min_samples_split:\n",
    "        node['right_split'] = node['left_split'] = terminal_node(right_child)\n",
    "    else:\n",
    "        node['right_split'] = find_split_point(right_child['X_bootstrap'], right_child['Y_bootstrap'], max_features)\n",
    "        split_node(node['right_split'], max_features, min_samples_split, max_depth, depth + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(X_bootstrap, Y_bootstrap, max_depth, min_samples_split, max_features):\n",
    "    root_node = find_split_point(X_bootstrap, Y_bootstrap, max_features)\n",
    "    split_node(root_node, max_features, min_samples_split, max_depth, 1)\n",
    "    return root_node\n",
    "\n",
    "def random_forest(X_train, Y_train, n_estimators, max_features, max_depth, min_samples_split):\n",
    "    tree_ls = list()\n",
    "    oob_ls = list()\n",
    "    for i in range(n_estimators):\n",
    "        X_bootstrap, Y_bootstrap, X_oob, Y_oob = draw_bootstrap(X_train, Y_train)\n",
    "        tree = build_tree(X_bootstrap, Y_bootstrap, max_features, max_depth, min_samples_split)\n",
    "        tree_ls.append(tree)\n",
    "        oob_error = oob_score(tree, X_oob, Y_oob)\n",
    "        oob_ls.append(oob_error)\n",
    "    print(\"OOB estimate: {:.2f}\".format(np.mean(oob_ls)))\n",
    "    return tree_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rf(tree_ls, X_test):\n",
    "    pred_ls = list()\n",
    "    for i in range(len(X_test)):\n",
    "        ensemble_preds = [predict_tree(tree, X_test.values[i]) for tree in tree_ls]\n",
    "        final_pred = max(ensemble_preds, key = ensemble_preds.count)\n",
    "        pred_ls.append(final_pred)\n",
    "    return np.array(pred_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 7\n",
    "max_features = 6\n",
    "max_depth = 15\n",
    "min_samples_split = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None, min_samples_split=2, min_samples_leaf=1):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.tree = self._build_tree(X, y, depth=0)\n",
    "\n",
    "    def _build_tree(self, X, y, depth):\n",
    "        num_samples , _ = X.shape\n",
    "        unique_classes = np.unique(y)\n",
    "\n",
    "        # Stopping conditions\n",
    "        if depth == self.max_depth or len(unique_classes) == 1 or num_samples < self.min_samples_split:\n",
    "            return {'class': self._most_common_class(y)}\n",
    "\n",
    "        # Find the best split\n",
    "        best_split = self._find_best_split(X, y)\n",
    "\n",
    "        if best_split.empty :\n",
    "            return {'class': self._most_common_class(y)}\n",
    "\n",
    "        feature_index, threshold = best_split\n",
    "        left_indices = X.iloc[:, feature_index] <= threshold\n",
    "        right_indices = ~left_indices\n",
    "\n",
    "        # Recursively build left and right subtrees\n",
    "        left_tree = self._build_tree(X[left_indices], y[left_indices], depth + 1)\n",
    "        right_tree = self._build_tree(X[right_indices], y[right_indices], depth + 1)\n",
    "\n",
    "        return {'feature_index': feature_index, 'threshold': threshold,\n",
    "                'left': left_tree, 'right': right_tree}\n",
    "\n",
    "    def _find_best_split(self, X, y):\n",
    "        num_samples, num_features = X.shape\n",
    "\n",
    "        if num_samples < self.min_samples_split:\n",
    "            return None\n",
    "\n",
    "        feature_indices = np.arange(num_features)\n",
    "        np.random.shuffle(feature_indices)\n",
    "\n",
    "        best_split = None\n",
    "        best_entropy = float('inf')\n",
    "\n",
    "        for feature_index in feature_indices[:num_features // 2]:\n",
    "            unique_values = np.unique(X.iloc[:, feature_index])\n",
    "            thresholds = (unique_values[:-1] + unique_values[1:]) / 2\n",
    "\n",
    "            for threshold in thresholds:\n",
    "                left_indices = X.iloc[:, feature_index] <= threshold\n",
    "                right_indices = ~left_indices\n",
    "\n",
    "                entropy = self._calculate_entropy(y[left_indices], y[right_indices])\n",
    "\n",
    "                if entropy < best_entropy:\n",
    "                    best_entropy = entropy\n",
    "                    best_split = (feature_index, threshold)\n",
    "\n",
    "        return best_split\n",
    "\n",
    "    def _calculate_entropy(self, y_left, y_right):\n",
    "        left_size, right_size = len(y_left), len(y_right)\n",
    "        total_size = left_size + right_size\n",
    "\n",
    "        entropy_left = -sum((np.sum(y_left == c) / left_size) * np.log2(np.sum(y_left == c) / left_size)\n",
    "                            for c in np.unique(y_left) if np.sum(y_left == c) > 0)\n",
    "\n",
    "        entropy_right = -sum((np.sum(y_right == c) / right_size) * np.log2(np.sum(y_right == c) / right_size)\n",
    "                             for c in np.unique(y_right) if np.sum(y_right == c) > 0)\n",
    "\n",
    "        entropy = (left_size / total_size) * entropy_left + (right_size / total_size) * entropy_right\n",
    "        return entropy\n",
    "\n",
    "    def _most_common_class(self, y):\n",
    "        return np.bincount(y).argmax()\n",
    "\n",
    "    def predict_instance(self, instance):\n",
    "        if self.tree is None:\n",
    "            raise ValueError(\"The tree has not been trained yet.\")\n",
    "\n",
    "        current_node = self.tree\n",
    "        while 'class' not in current_node:\n",
    "            if instance[current_node['feature_index']] <= current_node['threshold']:\n",
    "                current_node = current_node['left']\n",
    "            else:\n",
    "                current_node = current_node['right']\n",
    "\n",
    "        return current_node['class']\n",
    "\n",
    "\n",
    "class RandomForest:\n",
    "    def __init__(self, n_estimators=100, max_depth=None, min_samples_split=2, min_samples_leaf=1):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.forest = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.forest = []\n",
    "        for _ in range(self.n_estimators):\n",
    "            # Randomly sample with replacement for each tree\n",
    "            sample_indices = np.random.choice(len(X), size=len(X), replace=True)\n",
    "            X_sampled = X.iloc[sample_indices]\n",
    "            y_sampled = y.iloc[sample_indices]\n",
    "\n",
    "            # Create and train a decision tree\n",
    "            tree = DecisionTree(\n",
    "                max_depth=self.max_depth,\n",
    "                min_samples_split=self.min_samples_split,\n",
    "                min_samples_leaf=self.min_samples_leaf\n",
    "            )\n",
    "            tree.fit(X_sampled, y_sampled)\n",
    "\n",
    "            # Append the trained tree to the forest\n",
    "            self.forest.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Make predictions for each tree in the forest\n",
    "        predictions = np.array([tree.predict_instance(X.iloc[i]) for i in range(len(X))])\n",
    "\n",
    "        # Use majority voting to get the final prediction\n",
    "        final_predictions = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
    "\n",
    "        return final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForest(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mrandom_forest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [22], line 116\u001b[0m, in \u001b[0;36mRandomForest.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# Create and train a decision tree\u001b[39;00m\n\u001b[0;32m    111\u001b[0m tree \u001b[38;5;241m=\u001b[39m DecisionTree(\n\u001b[0;32m    112\u001b[0m     max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth,\n\u001b[0;32m    113\u001b[0m     min_samples_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_split,\n\u001b[0;32m    114\u001b[0m     min_samples_leaf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_leaf\n\u001b[0;32m    115\u001b[0m )\n\u001b[1;32m--> 116\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_sampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_sampled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m# Append the trained tree to the forest\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforest\u001b[38;5;241m.\u001b[39mappend(tree)\n",
      "Cell \u001b[1;32mIn [22], line 9\u001b[0m, in \u001b[0;36mDecisionTree.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [22], line 20\u001b[0m, in \u001b[0;36mDecisionTree._build_tree\u001b[1;34m(self, X, y, depth)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_most_common_class(y)}\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Find the best split\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m best_split \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_find_best_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best_split \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m :\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_most_common_class(y)}\n",
      "Cell \u001b[1;32mIn [22], line 56\u001b[0m, in \u001b[0;36mDecisionTree._find_best_split\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     53\u001b[0m left_indices \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39miloc[:, feature_index] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m threshold\n\u001b[0;32m     54\u001b[0m right_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39mleft_indices\n\u001b[1;32m---> 56\u001b[0m entropy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_calculate_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mleft_indices\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mright_indices\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m entropy \u001b[38;5;241m<\u001b[39m best_entropy:\n\u001b[0;32m     59\u001b[0m     best_entropy \u001b[38;5;241m=\u001b[39m entropy\n",
      "Cell \u001b[1;32mIn [22], line 68\u001b[0m, in \u001b[0;36mDecisionTree._calculate_entropy\u001b[1;34m(self, y_left, y_right)\u001b[0m\n\u001b[0;32m     65\u001b[0m left_size, right_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(y_left), \u001b[38;5;28mlen\u001b[39m(y_right)\n\u001b[0;32m     66\u001b[0m total_size \u001b[38;5;241m=\u001b[39m left_size \u001b[38;5;241m+\u001b[39m right_size\n\u001b[1;32m---> 68\u001b[0m entropy_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_left\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mleft_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_left\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mleft_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_left\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_left\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m entropy_right \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28msum\u001b[39m((np\u001b[38;5;241m.\u001b[39msum(y_right \u001b[38;5;241m==\u001b[39m c) \u001b[38;5;241m/\u001b[39m right_size) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog2(np\u001b[38;5;241m.\u001b[39msum(y_right \u001b[38;5;241m==\u001b[39m c) \u001b[38;5;241m/\u001b[39m right_size)\n\u001b[0;32m     72\u001b[0m                      \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39munique(y_right) \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(y_right \u001b[38;5;241m==\u001b[39m c) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     74\u001b[0m entropy \u001b[38;5;241m=\u001b[39m (left_size \u001b[38;5;241m/\u001b[39m total_size) \u001b[38;5;241m*\u001b[39m entropy_left \u001b[38;5;241m+\u001b[39m (right_size \u001b[38;5;241m/\u001b[39m total_size) \u001b[38;5;241m*\u001b[39m entropy_right\n",
      "Cell \u001b[1;32mIn [22], line 69\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     65\u001b[0m left_size, right_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(y_left), \u001b[38;5;28mlen\u001b[39m(y_right)\n\u001b[0;32m     66\u001b[0m total_size \u001b[38;5;241m=\u001b[39m left_size \u001b[38;5;241m+\u001b[39m right_size\n\u001b[0;32m     68\u001b[0m entropy_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28msum\u001b[39m((np\u001b[38;5;241m.\u001b[39msum(y_left \u001b[38;5;241m==\u001b[39m c) \u001b[38;5;241m/\u001b[39m left_size) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog2(np\u001b[38;5;241m.\u001b[39msum(y_left \u001b[38;5;241m==\u001b[39m c) \u001b[38;5;241m/\u001b[39m left_size)\n\u001b[1;32m---> 69\u001b[0m                     \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39munique(y_left) \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_left\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m)\n\u001b[0;32m     71\u001b[0m entropy_right \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28msum\u001b[39m((np\u001b[38;5;241m.\u001b[39msum(y_right \u001b[38;5;241m==\u001b[39m c) \u001b[38;5;241m/\u001b[39m right_size) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog2(np\u001b[38;5;241m.\u001b[39msum(y_right \u001b[38;5;241m==\u001b[39m c) \u001b[38;5;241m/\u001b[39m right_size)\n\u001b[0;32m     72\u001b[0m                      \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39munique(y_right) \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(y_right \u001b[38;5;241m==\u001b[39m c) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     74\u001b[0m entropy \u001b[38;5;241m=\u001b[39m (left_size \u001b[38;5;241m/\u001b[39m total_size) \u001b[38;5;241m*\u001b[39m entropy_left \u001b[38;5;241m+\u001b[39m (right_size \u001b[38;5;241m/\u001b[39m total_size) \u001b[38;5;241m*\u001b[39m entropy_right\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\generic.py:1527\u001b[0m, in \u001b[0;36mNDFrame.__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__nonzero__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1528\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe truth value of a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is ambiguous. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1529\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse a.empty, a.bool(), a.item(), a.any() or a.all().\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1530\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "random_forest.fit(X_train, Y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
